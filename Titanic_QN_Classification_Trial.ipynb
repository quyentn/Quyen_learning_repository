{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntrue_result = pd.read_csv('../input/gender_submission.csv')\n\ntrain.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e254b70b1e7ceb049416c1a1df0c15532caad69"},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d9a8dccc03536f0659992ade942a64b6411ecea"},"cell_type":"code","source":"# Some imputation need to be done with variables: Age, Cabin and Embarked\ntrain.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Missing records in Age are too many which may make the data unbalanced when we impute it with mean of age across the dataset. I recommended to treat this group as a separated bucket from all ages. These people may be in a lower class and don't have a lot of profile information when they buy a ticket"},{"metadata":{"trusted":true,"_uuid":"06038698d6655a409f8b244e880433992a760aea"},"cell_type":"code","source":"# describle 1 column to get quartile values\ntrain.Fare.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"raw","source":"train.Age.describe()"},{"metadata":{"_uuid":"f63794d95bcdca9e96c5854af0d9a8ebe62f8435"},"cell_type":"markdown","source":"__Variable Transformation__"},{"metadata":{"trusted":true,"_uuid":"4473cdf390d1494bd11cffc23906c19bd53e4d22"},"cell_type":"code","source":"import re\ndef clean_variable(df):\n    df.Age = df.Age.fillna(-0.5)\n    #df.Age = df.Age.fillna(df.Age.mean())\n    #df.Age = pd.cut(df.Age, (-1, 0, 20, 28, 38, 90), labels=['Unknown','1-quantile', '2-quantile', '3-quantile', '4-quantile'])\n    df.Age = pd.cut(df.Age, (-1,0, 18, 65, 100), labels=['Unknown','Child', 'Adult', 'Senior'])\n    df.Embarked = df.Embarked.fillna('N')\n    df.Cabin = df.Cabin.fillna('N')\n    df.Cabin = df.Cabin.apply(lambda x: x[0])\n    #df.Ticket = df.Ticket.apply(lambda x: x[0])\n    df.Fare = df.Fare.fillna(-0.5)\n    #df.Fare = pd.cut(df.Fare, (-1, 0, 8, 14, 31, 600), labels=['Unknown','1-quantile', '2-quantile', '3-quantile', '4-quantile'])\n    df.Fare = pd.cut(df.Fare,  (-1, 15, 1000), labels=['Economy', 'Business'])\n    df['Title'] = df.Name.apply(lambda x: x.split(', ')[1].split('.')[0])\n    df= df.drop(['Name' ], axis = 1)\n    return df\ntrain = clean_variable(train)\ntest = clean_variable(test)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"Age\", y=\"Survived\", hue=\"Sex\", data=train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"raw","source":"train.groupby(['Ticket']).size()"},{"metadata":{"trusted":true},"cell_type":"raw","source":"train.groupby(['Age','Survived']).size()"},{"metadata":{"trusted":true,"_uuid":"d0c424d98154535287debe3c1907fd08ced8b78d"},"cell_type":"code","source":"#unique titles in both train and test\npd.concat([train[['Title']],test[['Title']]],axis = 0).Title.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bddd2306caed08fc7ca944193139fa415f143fc9"},"cell_type":"code","source":"# normalize the titles\nnormalized_titles = {\n    \"Capt\":\"Officer\",        \"Col\":\"Officer\",    \"Major\":\"Officer\",    \"Dr\":\"Officer\",              \"Rev\":\"Officer\",\n    \"Jonkheer\":\"Royalty\",    \"Don\":\"Royalty\",    \"Sir\" :\"Royalty\",     \"the Countess\":\"Royalty\",    \"Dona\":\"Royalty\",    \"Lady\" :\"Royalty\",\n    \"Mme\":\"Mrs\",             \"Ms\":\"Mrs\",         \"Mrs\" :\"Mrs\",\n    \"Mlle\":\"Miss\",           \"Miss\" :\"Miss\",\n    \"Mr\" :\"Mr\",\n    \"Master\" :\"Master\"\n    }\n# map the normalized titles to the current titles \ntrain.Title = train.Title.map(normalized_titles)\ntest.Title = test.Title.map(normalized_titles)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7688e3ceb5c447fd8ea3cdc1c73c224ed776641"},"cell_type":"code","source":"pd.concat([train[['Title']],test[['Title']]],axis = 0).Title.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c14da47855bd2b615a775c655a2d80d41e93ed71"},"cell_type":"code","source":"sns.barplot(x=\"Cabin\", y=\"Survived\", hue=\"Sex\", data=train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89d1c873ccdf4c6bc5d8f0e8f986920fd3256e0d"},"cell_type":"markdown","source":"__Label Encoding__"},{"metadata":{"trusted":true,"_uuid":"8a9d7ca5ad441c2ed246fa3e8446e2de0fcf8ba1"},"cell_type":"code","source":"from sklearn import preprocessing\ndef encode_features(df_train, df_test):\n    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Title','Embarked']#,'Ticket'\n    df_combined = pd.concat([df_train[features], df_test[features]])\n    \n    for feature in features:\n        le = preprocessing.LabelEncoder()\n        le = le.fit(df_combined[feature])\n        df_train[feature] = le.transform(df_train[feature])\n        df_test[feature] = le.transform(df_test[feature])\n    return df_train, df_test\n    \ntrain, test = encode_features(train, test)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"16df0fc129810347a0883f25c63b47bd0d22d0e8"},"cell_type":"markdown","source":"__Splitting up the Training Data__"},{"metadata":{"trusted":true,"_uuid":"92a293336fdaa89acad021643cb7406cca53dfdd"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_all = train.drop(['Survived', 'PassengerId','Ticket'], axis=1)\ny_all = train['Survived']\n\nnum_test = 0.30\nX_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=123)\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe47092ec7ef98e6e51f1ca9879c48f50b11191a"},"cell_type":"markdown","source":"__Fitting and Tuning an Algorithm__"},{"metadata":{},"cell_type":"markdown","source":"__DecisionTreeClassifier__ (https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"},{"metadata":{"trusted":true,"_uuid":"a0ec84909095382e531e107a393ffe8b23bd6ea2"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.model_selection import GridSearchCV\n\n# Choose the type of classifier. \nclf = DecisionTreeClassifier()\n\n# Choose some parameter combinations to try\nparameters = {'criterion': ['entropy', 'gini'],\n              'splitter': ['best','random'],\n              'max_depth': [2, 3, 5, 10, 20], \n              'min_samples_split': [3, 5, 8, 10],\n              'min_samples_leaf': [1,2,5], \n              'max_features': ['log2','sqrt','auto'], \n              'random_state': [1234]\n             }\n# Type of scoring used to compare parameter combinations\nacc_scorer = make_scorer(accuracy_score)\n\n# Run the grid search\ngrid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer,cv=3,iid = True)\ngrid_obj = grid_obj.fit(X_train, y_train)\n\n# Set the clf to the best combination of parameters\nclf = grid_obj.best_estimator_\n\n# Fit the best algorithm to the data. \nclf.fit(X_train, y_train)\nprint(clf)\n\ntrain_predictions = clf.predict(X_train)\nprint('train accuracy: '+str(accuracy_score(y_train, train_predictions)))\ntest_predictions = clf.predict(X_test)\nprint('test accuracy: '+str(accuracy_score(y_test, test_predictions)))\n\n#Feature importances\nfeature_importance_df = pd.DataFrame(\n                    {'Features': X_train.columns,\n                     'Importances': clf.feature_importances_\n                    }).sort_values(by=['Importances'],ascending=False)\nfeature_importance_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature importance plot\nsns.barplot(x=\"Importances\", y=\"Features\", data=feature_importance_df,palette=\"Blues_d\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12ac6a6b65f414e58933cd4dc05f2b9a42070461"},"cell_type":"markdown","source":"__Validate with KFold__\n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n\nParameters:\t\n- n_splits : int, default=3: Number of folds. Must be at least 2. - Changed in version 0.20: n_splits default value will change from 3 to 5 in v0.22.\n- shuffle : boolean, optional: Whether to shuffle the data before splitting into batches.\n- random_state : int, RandomState instance or None, optional, default=None. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random. Used when shuffle == True.\n\nMethods:\n- get_n_splits([X, y, groups])\tReturns the number of splitting iterations in the cross-validator\n- split(X[, y, groups])\tGenerate indices to split data into training and test set."},{"metadata":{"trusted":true,"_uuid":"8bcbd39839b24955fa41a6b85a1386acdca1a92b"},"cell_type":"code","source":"from sklearn.model_selection  import KFold\n\ndef run_kfold(clf):\n    kf = KFold(n_splits=5) # n_sample in each split will be 4:1 (total = 5) for train and test\n    kf.get_n_splits(X_all)\n    outcomes = []\n    fold = 0\n    for train_index, test_index in kf.split(X_all):\n        fold += 1\n        X_train, X_test = X_all.values[train_index], X_all.values[test_index]\n        y_train, y_test = y_all.values[train_index], y_all.values[test_index]\n        clf.fit(X_train, y_train)\n        predictions = clf.predict(X_test)\n        accuracy = accuracy_score(y_test, predictions)\n        outcomes.append(accuracy)\n        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy))     \n    mean_outcome = np.mean(outcomes)\n    print(\"Mean Accuracy: {0}\".format(mean_outcome))\n\nrun_kfold(clf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5aa0f38bf119cbe5ff2a43dbb674e1754c59a761"},"cell_type":"markdown","source":"__Predict the Actual Test Data__\n\nAnd now for the moment of truth. Make the predictions, export the CSV file, and upload them to Kaggle."},{"metadata":{"trusted":true,"_uuid":"c2db8efcfcda694670d9836a2d637c85890a06e2"},"cell_type":"code","source":"ids = test['PassengerId']\npredictions = clf.predict(test.drop(['PassengerId','Ticket'], axis=1))\n\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('titanic-predictions.csv', index = False)\noutput.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8e798a17b51cb5940c84df1d5129a44518cc489"},"cell_type":"code","source":"#Check same PassengerId\ny_pred_id = output['PassengerId'].tolist()\ny_true_id = true_result['PassengerId'].tolist()\nprint('If PassengerId is in the right order: '+str(y_pred_id == y_true_id))\n#Public score\ny_pred = output['Survived'].tolist()\ny_true = true_result['Survived'].tolist()\nprint('Public score: '+str(accuracy_score(y_true, y_pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}